{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58804d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensors\n",
    "# Basic building block\n",
    "\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9103b8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scalar value: 12.10\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "scalar = torch.tensor(12.1)\n",
    "print(f\"scalar value: {scalar:>.2f}\")\n",
    "\n",
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "\n",
    "print(x_data)\n",
    "print(type(x_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfb4756d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "\n",
    "print(np_array)\n",
    "print(x_np)\n",
    "print(type(x_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ab948dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 1]]\n",
      "tensor([[1, 2],\n",
      "        [3, 1]])\n"
     ]
    }
   ],
   "source": [
    "# tensor data is reference of the numpy array. not copied\n",
    "np_array[1, 1] = 1\n",
    "\n",
    "print(np_array)\n",
    "print(x_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c753217e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "tensor([[0.2348, 0.4360],\n",
      "        [0.2825, 0.0781]])\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data)  # x_data is tensor\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float)\n",
    "\n",
    "print(x_ones)\n",
    "print(x_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6174e945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0107, 0.0151, 0.4756],\n",
      "        [0.7289, 0.2233, 0.4001]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# from shape\n",
    "rand_tensor = torch.rand(2, 3)\n",
    "ones_tensor = torch.ones((3, 2)) # 3x2 matrix\n",
    "zeros_tensor = torch.zeros(5)  # row vector\n",
    "\n",
    "print(rand_tensor)\n",
    "print(ones_tensor)\n",
    "print(zeros_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a4e0d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.11074231 0.1150556  0.5756198 ]\n",
      " [0.8289369  0.323297   0.5001325 ]]\n",
      "<class 'numpy.ndarray'>\n",
      "[[0.21074231 0.2150556  0.67561984]\n",
      " [0.9289369  0.423297   0.6001325 ]]\n"
     ]
    }
   ],
   "source": [
    "# with numpy\n",
    "np_rand = rand_tensor.numpy()\n",
    "print(np_rand)\n",
    "print(type(np_rand))\n",
    "\n",
    "# change tensor elements\n",
    "rand_tensor.add_(0.1)\n",
    "# reflects to the numpy array\n",
    "print(np_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e44edaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data's default device: cpu\n",
      "cuda device is available\n",
      "x_data's changed device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# tensors' device\n",
    "print(f\"x_data's default device: {x_data.device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(\"cuda device is available\")\n",
    "    x_data = x_data.to(\"cuda\")\n",
    "print(f\"x_data's changed device: {x_data.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2778516a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1.])\n",
      "tensor([0.0151, 0.2233])\n",
      "tensor([0.7289, 0.2233, 0.4001])\n"
     ]
    }
   ],
   "source": [
    "# slicing tensor\n",
    "\n",
    "# tensor[row,col]\n",
    "print(ones_tensor[0,:])\n",
    "print(rand_tensor[:,1])\n",
    "print(rand_tensor[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98df8ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5014, 0.5014],\n",
      "        [1.3524, 1.3524]])\n",
      "tensor([[0.7397, 0.2384, 0.8758],\n",
      "        [0.7397, 0.2384, 0.8758],\n",
      "        [0.7397, 0.2384, 0.8758]])\n"
     ]
    }
   ],
   "source": [
    "# matrix multiplication\n",
    "y1 = rand_tensor @ ones_tensor\n",
    "y2 = ones_tensor.matmul(rand_tensor)\n",
    "\n",
    "print(y1)\n",
    "print(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0f954bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# element wise multiplication\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m y1 \u001b[38;5;241m=\u001b[39m \u001b[43mrand_tensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mones_tensor\u001b[49m\n\u001b[1;32m      3\u001b[0m y2 \u001b[38;5;241m=\u001b[39m ones_tensor\u001b[38;5;241m.\u001b[39mmul(rand_tensor)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(y1)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# element wise multiplication (error)\n",
    "y1 = rand_tensor * ones_tensor\n",
    "y2 = ones_tensor.mul(rand_tensor)\n",
    "\n",
    "print(y1)\n",
    "print(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd0bae19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1540e-04, 2.2667e-04, 2.2621e-01],\n",
      "        [5.3135e-01, 4.9862e-02, 1.6011e-01]])\n",
      "tensor([[1.1540e-04, 2.2667e-04, 2.2621e-01],\n",
      "        [5.3135e-01, 4.9862e-02, 1.6011e-01]])\n"
     ]
    }
   ],
   "source": [
    "# element wise multiplication (error)\n",
    "y1 = rand_tensor * rand_tensor\n",
    "y2 = rand_tensor.mul(rand_tensor)\n",
    "print(y1)\n",
    "print(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28881ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg = ones_tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item)\n",
    "print(agg.shape)\n",
    "print(type(agg))\n",
    "print(type(agg_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac0f11cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.],\n",
      "        [3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "# in-place operation\n",
    "ones_tensor.add_(2)\n",
    "print(ones_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3d65c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1670, 0.4094, 0.0658],\n",
      "        [0.3727, 0.0372, 0.2568]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "float_16_tensor = torch.rand(size=(2, 3), dtype=torch.float16)\n",
    "float_32_tensor = torch.rand(size=(2, 3), dtype=torch.float32)\n",
    "\n",
    "z1 = float_16_tensor * float_32_tensor\n",
    "print(z1)\n",
    "print(z1.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01dbfcfb",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m float_16_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16)\n\u001b[1;32m      2\u001b[0m float_32_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m), device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m----> 4\u001b[0m z1 \u001b[38;5;241m=\u001b[39m \u001b[43mfloat_16_tensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfloat_32_tensor\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(z1)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(z1\u001b[38;5;241m.\u001b[39mdtype)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "# errror case\n",
    "float_16_tensor = torch.rand(size=(2, 3), dtype=torch.float16)\n",
    "float_32_tensor = torch.rand(size=(2, 3), device=\"cuda:0\", dtype=torch.float32)\n",
    "\n",
    "z1 = float_16_tensor * float_32_tensor\n",
    "print(z1)\n",
    "print(z1.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d3886c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2107, 0.2151, 0.6756],\n",
      "        [0.9289, 0.4233, 0.6001]])\n",
      "tensor(0.2107)\n",
      "tensor(0.9289)\n",
      "tensor(0)\n",
      "tensor(3)\n"
     ]
    }
   ],
   "source": [
    "print(rand_tensor)\n",
    "\n",
    "# min/max\n",
    "print(rand_tensor.min())\n",
    "print(rand_tensor.max())\n",
    "\n",
    "# Positional min/max\n",
    "print(rand_tensor.argmin())\n",
    "print(rand_tensor.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7bb1a845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4., 5., 6., 7.])\n",
      "torch.Size([7])\n",
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [7.]])\n",
      "torch.Size([7, 1])\n",
      "tensor([1., 2., 3., 4., 5., 6., 7.])\n"
     ]
    }
   ],
   "source": [
    "# reshape\n",
    "x = torch.arange(1, 8, dtype=torch.float32)\n",
    "print(x.shape)\n",
    "print(x)\n",
    "\n",
    "x_reshaped = x.reshape(7, 1)\n",
    "print(x_reshaped.shape)\n",
    "print(x_reshaped)\n",
    "\n",
    "# original tensor is not changed\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c61c5233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3., 4., 5., 6., 7.],\n",
      "        [1., 2., 3., 4., 5., 6., 7.],\n",
      "        [1., 2., 3., 4., 5., 6., 7.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [2., 2., 2.],\n",
      "        [3., 3., 3.],\n",
      "        [4., 4., 4.],\n",
      "        [5., 5., 5.],\n",
      "        [6., 6., 6.],\n",
      "        [7., 7., 7.]])\n"
     ]
    }
   ],
   "source": [
    "# stack\n",
    "x_stacked = torch.stack([x, x, x], dim=0)\n",
    "print(x_stacked)\n",
    "\n",
    "x_stacked = torch.stack([x, x, x], dim=1)\n",
    "print(x_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d8050848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3049, 0.4399, 0.2331, 0.0420, 0.8369], device='cuda:0')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m gpu_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m5\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(gpu_tensor)\n\u001b[0;32m----> 5\u001b[0m np_gpu_array \u001b[38;5;241m=\u001b[39m \u001b[43mgpu_tensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(np_gpu_array)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "# tensor on gpu to numpy?\n",
    "gpu_tensor = torch.rand(5, device=\"cuda\")\n",
    "print(gpu_tensor)\n",
    "\n",
    "np_gpu_array = gpu_tensor.numpy()\n",
    "print(np_gpu_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0583ed8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3049381  0.43990096 0.23314981 0.04202771 0.8368703 ]\n"
     ]
    }
   ],
   "source": [
    "# so,\n",
    "np_cpu_array = gpu_tensor.cpu().numpy()\n",
    "print(np_cpu_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c163763d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
